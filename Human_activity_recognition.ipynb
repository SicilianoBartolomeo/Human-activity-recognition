{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SicilianoBartolomeo/Human-activity-recognition/blob/main/Human_activity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8BKXisNUNPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2a5b5a58-471f-4af3-932f-01137eb5ce5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "\n",
            "\n",
            "This error most likely means that this notebook is not configured to use a GPU.  Change this in Notebook Settings via the command palette (cmd/ctrl-shift-P) or the Edit menu.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-12a96375708b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;34m'configured to use a GPU.  Change this in Notebook Settings via the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('HARDataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('HARDataset')"
      ],
      "metadata": {
        "id": "-FftW_V8nxgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd HARDataset\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER__hCAVyOy8",
        "outputId": "19a039e9-435a-42b6-be38-5d879c397313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HARDataset  HARDataset.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "Nry75kM_vWjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "\n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        "\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "metadata": {
        "id": "Cklqv9TxvZKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = load_dataset('HARDataset/')\n",
        "\n",
        "print('\\ntrainX\\n', data[0])\n",
        "print('\\ntrainY\\n', data[1])\n",
        "print('\\ntestX\\n', data[2])\n",
        "print('\\ntestY\\n', data[3])\n",
        "\n",
        "inputs = np.concatenate((data[0], data[2]), axis=0)\n",
        "targets = np.concatenate((data[1], data[3]), axis=0)\n",
        "print()\n",
        "print(inputs)\n",
        "print()\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "BkM-JXQywDxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a435e81-59cf-4bb6-a05a-6447831073ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            "\n",
            "trainX\n",
            " [[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 7.548917e-01 -1.711829e-01  1.745865e-01 ...  1.183561e-01\n",
            "    4.267019e-01  3.008475e-01]\n",
            "  [ 8.043137e-01 -1.999375e-01  2.324243e-01 ...  1.378901e-01\n",
            "    3.223201e-01  3.511780e-01]\n",
            "  [ 8.317140e-01 -2.319457e-01  2.576066e-01 ...  1.774201e-01\n",
            "    2.331586e-01  2.723513e-01]\n",
            "  ...\n",
            "  [ 6.956257e-01 -2.217656e-01  1.112952e-01 ... -7.609545e-01\n",
            "    6.840804e-01  2.543444e-01]\n",
            "  [ 7.479103e-01 -2.811496e-01  1.263023e-01 ... -6.779630e-01\n",
            "    6.291636e-01  2.814308e-01]\n",
            "  [ 7.767680e-01 -3.275988e-01  1.886212e-01 ... -6.275012e-01\n",
            "    4.812542e-01  2.542062e-01]]\n",
            "\n",
            " [[ 9.279268e-01 -2.238010e-01  2.628140e-01 ... -3.788723e-01\n",
            "    1.642781e-01  2.175042e-01]\n",
            "  [ 9.129872e-01 -2.210407e-01  2.954154e-01 ... -3.738884e-01\n",
            "    6.393670e-02  1.584971e-01]\n",
            "  [ 9.246597e-01 -1.839923e-01  3.376098e-01 ... -3.301252e-01\n",
            "   -9.430612e-02  1.868787e-01]\n",
            "  ...\n",
            "  [ 6.753473e-01 -1.620087e-01  1.289247e-01 ... -4.254607e-01\n",
            "    6.504409e-01  1.762117e-01]\n",
            "  [ 6.603377e-01 -2.020367e-01  1.722512e-01 ... -4.755471e-01\n",
            "    4.097342e-01  1.635609e-01]\n",
            "  [ 7.193530e-01 -2.291273e-01  2.100712e-01 ... -4.129589e-01\n",
            "    1.998230e-01  1.887340e-01]]\n",
            "\n",
            " [[ 7.980909e-01 -3.060512e-01  2.093865e-01 ... -4.767788e-01\n",
            "    2.889329e-01  2.277976e-01]\n",
            "  [ 8.192417e-01 -2.666046e-01  2.310711e-01 ... -2.679120e-01\n",
            "    1.712000e-01  1.034757e-01]\n",
            "  [ 8.658821e-01 -2.053607e-01  3.341906e-01 ... -1.905664e-01\n",
            "    1.424723e-01 -7.565458e-02]\n",
            "  ...\n",
            "  [ 8.980947e-01 -3.977751e-01 -1.561050e-01 ...  1.004855e+00\n",
            "    1.156645e+00 -3.625121e-01]\n",
            "  [ 8.283723e-01 -3.492473e-01 -1.227979e-01 ...  1.015589e+00\n",
            "    1.100750e+00 -3.839895e-01]\n",
            "  [ 8.002428e-01 -3.323721e-01 -8.357159e-02 ...  1.047599e+00\n",
            "    1.011324e+00 -3.358840e-01]]]\n",
            "\n",
            "trainY\n",
            " [[0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]]\n",
            "\n",
            "testX\n",
            " [[[ 1.041216   -0.2697959   0.02377977 ...  0.4374637   0.5313492\n",
            "    0.1365279 ]\n",
            "  [ 1.041803   -0.280025    0.07629271 ...  0.4682641   0.7210685\n",
            "    0.09762239]\n",
            "  [ 1.039086   -0.2926631   0.1474754  ...  0.4982574   0.5203284\n",
            "    0.08355578]\n",
            "  ...\n",
            "  [ 0.9930164  -0.2599865   0.1443951  ... -0.00505586 -0.07734212\n",
            "    0.03225787]\n",
            "  [ 0.9932414  -0.2620643   0.1447033  ... -0.02043194 -0.072973\n",
            "    0.02700848]\n",
            "  [ 0.9943906  -0.2641348   0.1454939  ... -0.02999741 -0.07064875\n",
            "    0.03054609]]\n",
            "\n",
            " [[ 0.9991921  -0.2649349   0.1256164  ...  0.1702878  -0.06137388\n",
            "    0.05509624]\n",
            "  [ 0.9946787  -0.2532142   0.1256249  ...  0.1752221  -0.09536355\n",
            "    0.04334361]\n",
            "  [ 0.9935518  -0.2565887   0.1163814  ...  0.1308618  -0.1464495\n",
            "    0.05239831]\n",
            "  ...\n",
            "  [ 1.001861   -0.2619359   0.1527878  ... -0.01746929 -0.04128761\n",
            "    0.05831106]\n",
            "  [ 0.9975208  -0.2713225   0.1398428  ... -0.02124615 -0.03632182\n",
            "    0.05100018]\n",
            "  [ 0.9928615  -0.2799715   0.1213135  ... -0.02108687 -0.01963055\n",
            "    0.03697936]]\n",
            "\n",
            " [[ 0.9975931  -0.2639912   0.1507741  ... -0.0387265  -0.06024968\n",
            "    0.02928903]\n",
            "  [ 0.9989703  -0.2638194   0.1539427  ... -0.04728239 -0.0517562\n",
            "    0.02536597]\n",
            "  [ 0.9970574  -0.2638495   0.1441536  ... -0.05390624 -0.05042757\n",
            "    0.02482575]\n",
            "  ...\n",
            "  [ 0.9918802  -0.2836712   0.132678   ... -0.03089945 -0.03714901\n",
            "    0.02032818]\n",
            "  [ 0.9906626  -0.280597    0.1326941  ... -0.03537277 -0.03409071\n",
            "    0.01645414]\n",
            "  [ 0.9882446  -0.2822329   0.1321175  ... -0.03536986 -0.0304065\n",
            "    0.01416688]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.8213505  -0.2484623  -0.2216934  ...  0.8457912   0.06672695\n",
            "   -0.7659807 ]\n",
            "  [ 0.7991996  -0.2232599  -0.2045561  ...  0.8385992  -0.2486773\n",
            "   -0.8401374 ]\n",
            "  [ 0.8004623  -0.179017   -0.2568719  ...  0.8132189  -0.448804\n",
            "   -0.857202  ]\n",
            "  ...\n",
            "  [ 1.46317    -0.5515283  -0.2723974  ... -0.9962677   0.9452816\n",
            "   -0.1211067 ]\n",
            "  [ 1.179223   -0.5472997  -0.06773376 ... -1.011002    0.4431138\n",
            "   -0.2100397 ]\n",
            "  [ 0.8504963  -0.4900368   0.1378256  ... -0.68338    -0.4617246\n",
            "   -0.129691  ]]\n",
            "\n",
            " [[ 1.037668   -0.3971532  -0.3940817  ... -0.8444065   0.3994681\n",
            "   -0.5342947 ]\n",
            "  [ 0.8780725  -0.2848634  -0.3151097  ... -0.6438182   0.2690953\n",
            "   -0.7094171 ]\n",
            "  [ 0.8963897  -0.2635297  -0.213904   ... -0.5957706   0.2522084\n",
            "   -0.7025197 ]\n",
            "  ...\n",
            "  [ 1.156389   -0.2283478  -0.00351205 ... -0.4749118   0.0248663\n",
            "    0.2332489 ]\n",
            "  [ 1.243857   -0.258322   -0.1117857  ... -0.5493259  -0.1060269\n",
            "    0.3001525 ]\n",
            "  [ 1.323546   -0.3472416  -0.2760682  ... -0.6220308  -0.2043685\n",
            "    0.4318673 ]]\n",
            "\n",
            " [[ 0.7713622  -0.4250499  -0.05327655 ... -0.3324763  -1.093888\n",
            "   -0.1398256 ]\n",
            "  [ 0.9000949  -0.4375916  -0.4020727  ... -0.3165543  -1.066005\n",
            "   -0.1855697 ]\n",
            "  [ 0.8681034  -0.4421595  -0.5197379  ... -0.5837689  -0.5695502\n",
            "   -0.2221543 ]\n",
            "  ...\n",
            "  [ 0.9188616  -0.3516799  -0.07253919 ...  0.09593065 -0.0210238\n",
            "   -0.05134232]\n",
            "  [ 0.9494752  -0.267526   -0.05097549 ...  0.09070755 -0.04189301\n",
            "   -0.0788771 ]\n",
            "  [ 0.9578348  -0.1941603  -0.02892477 ...  0.05594314 -0.1024019\n",
            "   -0.04626822]]]\n",
            "\n",
            "testY\n",
            " [[0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]]\n",
            "\n",
            "[[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 8.213505e-01 -2.484623e-01 -2.216934e-01 ...  8.457912e-01\n",
            "    6.672695e-02 -7.659807e-01]\n",
            "  [ 7.991996e-01 -2.232599e-01 -2.045561e-01 ...  8.385992e-01\n",
            "   -2.486773e-01 -8.401374e-01]\n",
            "  [ 8.004623e-01 -1.790170e-01 -2.568719e-01 ...  8.132189e-01\n",
            "   -4.488040e-01 -8.572020e-01]\n",
            "  ...\n",
            "  [ 1.463170e+00 -5.515283e-01 -2.723974e-01 ... -9.962677e-01\n",
            "    9.452816e-01 -1.211067e-01]\n",
            "  [ 1.179223e+00 -5.472997e-01 -6.773376e-02 ... -1.011002e+00\n",
            "    4.431138e-01 -2.100397e-01]\n",
            "  [ 8.504963e-01 -4.900368e-01  1.378256e-01 ... -6.833800e-01\n",
            "   -4.617246e-01 -1.296910e-01]]\n",
            "\n",
            " [[ 1.037668e+00 -3.971532e-01 -3.940817e-01 ... -8.444065e-01\n",
            "    3.994681e-01 -5.342947e-01]\n",
            "  [ 8.780725e-01 -2.848634e-01 -3.151097e-01 ... -6.438182e-01\n",
            "    2.690953e-01 -7.094171e-01]\n",
            "  [ 8.963897e-01 -2.635297e-01 -2.139040e-01 ... -5.957706e-01\n",
            "    2.522084e-01 -7.025197e-01]\n",
            "  ...\n",
            "  [ 1.156389e+00 -2.283478e-01 -3.512052e-03 ... -4.749118e-01\n",
            "    2.486630e-02  2.332489e-01]\n",
            "  [ 1.243857e+00 -2.583220e-01 -1.117857e-01 ... -5.493259e-01\n",
            "   -1.060269e-01  3.001525e-01]\n",
            "  [ 1.323546e+00 -3.472416e-01 -2.760682e-01 ... -6.220308e-01\n",
            "   -2.043685e-01  4.318673e-01]]\n",
            "\n",
            " [[ 7.713622e-01 -4.250499e-01 -5.327655e-02 ... -3.324763e-01\n",
            "   -1.093888e+00 -1.398256e-01]\n",
            "  [ 9.000949e-01 -4.375916e-01 -4.020727e-01 ... -3.165543e-01\n",
            "   -1.066005e+00 -1.855697e-01]\n",
            "  [ 8.681034e-01 -4.421595e-01 -5.197379e-01 ... -5.837689e-01\n",
            "   -5.695502e-01 -2.221543e-01]\n",
            "  ...\n",
            "  [ 9.188616e-01 -3.516799e-01 -7.253919e-02 ...  9.593065e-02\n",
            "   -2.102380e-02 -5.134232e-02]\n",
            "  [ 9.494752e-01 -2.675260e-01 -5.097549e-02 ...  9.070755e-02\n",
            "   -4.189301e-02 -7.887710e-02]\n",
            "  [ 9.578348e-01 -1.941603e-01 -2.892477e-02 ...  5.594314e-02\n",
            "   -1.024019e-01 -4.626822e-02]]]\n",
            "\n",
            "[[0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data[0][7351][127]\n",
        "#inputs[7351][127]\n",
        "from keras.datasets import cifar10\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "  print(\"-------------------------------------------------------------------------------s\")\n",
        "  print(\"train\")\n",
        "  print(inputs[train])\n",
        "  print(\"test\")\n",
        "  print(inputs[test])\n"
      ],
      "metadata": {
        "id": "Pt8NiVpYWpji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f738f3-190c-4bad-9721-d5bdf57f65c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.017682e+00 -1.334039e-01  9.515180e-02 ... -3.751574e-02\n",
            "   -1.288632e-02 -8.727416e-04]\n",
            "  [ 1.018149e+00 -1.343639e-01  9.541539e-02 ... -3.309700e-02\n",
            "   -1.691822e-02 -5.481970e-03]\n",
            "  [ 1.019854e+00 -1.352028e-01  8.827355e-02 ... -3.036013e-02\n",
            "   -1.618518e-02 -4.678230e-03]\n",
            "  ...\n",
            "  [ 1.019916e+00 -1.319863e-01  8.576054e-02 ... -2.015042e-02\n",
            "    1.401018e-03 -8.408470e-03]\n",
            "  [ 1.019602e+00 -1.345073e-01  8.327454e-02 ... -1.695977e-02\n",
            "    4.472376e-04 -1.115822e-02]\n",
            "  [ 1.020735e+00 -1.333157e-01  8.140418e-02 ... -7.120059e-03\n",
            "    1.950985e-03 -1.298664e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 8.213505e-01 -2.484623e-01 -2.216934e-01 ...  8.457912e-01\n",
            "    6.672695e-02 -7.659807e-01]\n",
            "  [ 7.991996e-01 -2.232599e-01 -2.045561e-01 ...  8.385992e-01\n",
            "   -2.486773e-01 -8.401374e-01]\n",
            "  [ 8.004623e-01 -1.790170e-01 -2.568719e-01 ...  8.132189e-01\n",
            "   -4.488040e-01 -8.572020e-01]\n",
            "  ...\n",
            "  [ 1.463170e+00 -5.515283e-01 -2.723974e-01 ... -9.962677e-01\n",
            "    9.452816e-01 -1.211067e-01]\n",
            "  [ 1.179223e+00 -5.472997e-01 -6.773376e-02 ... -1.011002e+00\n",
            "    4.431138e-01 -2.100397e-01]\n",
            "  [ 8.504963e-01 -4.900368e-01  1.378256e-01 ... -6.833800e-01\n",
            "   -4.617246e-01 -1.296910e-01]]\n",
            "\n",
            " [[ 1.037668e+00 -3.971532e-01 -3.940817e-01 ... -8.444065e-01\n",
            "    3.994681e-01 -5.342947e-01]\n",
            "  [ 8.780725e-01 -2.848634e-01 -3.151097e-01 ... -6.438182e-01\n",
            "    2.690953e-01 -7.094171e-01]\n",
            "  [ 8.963897e-01 -2.635297e-01 -2.139040e-01 ... -5.957706e-01\n",
            "    2.522084e-01 -7.025197e-01]\n",
            "  ...\n",
            "  [ 1.156389e+00 -2.283478e-01 -3.512052e-03 ... -4.749118e-01\n",
            "    2.486630e-02  2.332489e-01]\n",
            "  [ 1.243857e+00 -2.583220e-01 -1.117857e-01 ... -5.493259e-01\n",
            "   -1.060269e-01  3.001525e-01]\n",
            "  [ 1.323546e+00 -3.472416e-01 -2.760682e-01 ... -6.220308e-01\n",
            "   -2.043685e-01  4.318673e-01]]\n",
            "\n",
            " [[ 7.713622e-01 -4.250499e-01 -5.327655e-02 ... -3.324763e-01\n",
            "   -1.093888e+00 -1.398256e-01]\n",
            "  [ 9.000949e-01 -4.375916e-01 -4.020727e-01 ... -3.165543e-01\n",
            "   -1.066005e+00 -1.855697e-01]\n",
            "  [ 8.681034e-01 -4.421595e-01 -5.197379e-01 ... -5.837689e-01\n",
            "   -5.695502e-01 -2.221543e-01]\n",
            "  ...\n",
            "  [ 9.188616e-01 -3.516799e-01 -7.253919e-02 ...  9.593065e-02\n",
            "   -2.102380e-02 -5.134232e-02]\n",
            "  [ 9.494752e-01 -2.675260e-01 -5.097549e-02 ...  9.070755e-02\n",
            "   -4.189301e-02 -7.887710e-02]\n",
            "  [ 9.578348e-01 -1.941603e-01 -2.892477e-02 ...  5.594314e-02\n",
            "   -1.024019e-01 -4.626822e-02]]]\n",
            "test\n",
            "[[[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " [[ 1.019952e+00 -1.287306e-01  8.084140e-02 ... -1.942932e-02\n",
            "   -8.612378e-03 -1.574010e-03]\n",
            "  [ 1.019616e+00 -1.278461e-01  7.912684e-02 ... -1.909099e-02\n",
            "   -8.146719e-03  2.007077e-04]\n",
            "  [ 1.020933e+00 -1.282300e-01  7.829138e-02 ... -1.481631e-02\n",
            "   -5.376620e-03 -9.700938e-04]\n",
            "  ...\n",
            "  [ 1.019425e+00 -1.245585e-01  8.132876e-02 ...  1.145144e-02\n",
            "   -5.571703e-03 -4.491357e-03]\n",
            "  [ 1.018896e+00 -1.214556e-01  8.539719e-02 ...  1.268365e-02\n",
            "    3.417937e-03 -3.441367e-03]\n",
            "  [ 1.016787e+00 -1.234940e-01  8.881566e-02 ...  1.560483e-02\n",
            "    1.079681e-02 -1.008158e-02]]\n",
            "\n",
            " [[ 1.021278e+00 -1.327355e-01  7.878516e-02 ... -5.801088e-03\n",
            "    5.577377e-03 -1.738067e-02]\n",
            "  [ 1.018878e+00 -1.326756e-01  8.098401e-02 ... -1.043543e-02\n",
            "    5.155942e-03 -2.114078e-02]\n",
            "  [ 1.019219e+00 -1.317610e-01  8.581952e-02 ... -1.325185e-02\n",
            "    9.489843e-04 -1.863582e-02]\n",
            "  ...\n",
            "  [ 1.020341e+00 -1.195249e-01  8.812156e-02 ...  1.651920e-03\n",
            "   -1.032725e-02  9.726943e-03]\n",
            "  [ 1.020415e+00 -1.188070e-01  8.816615e-02 ...  3.842529e-03\n",
            "   -1.468221e-02  1.790335e-02]\n",
            "  [ 1.021908e+00 -1.181566e-01  8.748509e-02 ...  9.031974e-03\n",
            "   -1.171324e-02  2.442312e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 7.655386e-01 -9.188369e-02 -2.611963e-02 ... -1.286000e+00\n",
            "    2.763508e-01 -3.901660e-02]\n",
            "  [ 7.159431e-01 -8.846128e-02 -3.615480e-03 ... -1.324865e+00\n",
            "    2.096432e-01 -3.179796e-02]\n",
            "  [ 7.017566e-01 -8.330732e-02  2.805272e-02 ... -1.310755e+00\n",
            "    7.924153e-02 -3.316481e-02]\n",
            "  ...\n",
            "  [ 1.022954e+00 -4.566423e-02 -1.328992e-01 ... -7.915372e-01\n",
            "    3.978650e-01  4.606910e-01]\n",
            "  [ 1.027174e+00 -1.604214e-01  7.948668e-02 ... -5.656227e-01\n",
            "    1.283070e-01  4.481105e-01]\n",
            "  [ 8.926741e-01 -2.079787e-01  7.964739e-02 ... -4.768266e-01\n",
            "    1.195638e-02  3.615130e-01]]\n",
            "\n",
            " [[ 7.657176e-01 -2.065874e-01  2.926086e-02 ... -5.108578e-01\n",
            "    3.182368e-02  2.943121e-01]\n",
            "  [ 6.800446e-01 -1.512725e-01  3.748998e-02 ... -5.357863e-01\n",
            "   -8.976828e-02  2.036407e-01]\n",
            "  [ 5.724041e-01 -6.159548e-02 -1.338005e-03 ... -6.504470e-01\n",
            "   -4.400094e-01  2.008237e-01]\n",
            "  ...\n",
            "  [ 1.576537e+00 -4.071494e-02 -3.255716e-01 ... -1.203918e+00\n",
            "   -6.119723e-01 -4.052641e-02]\n",
            "  [ 1.484322e+00 -1.995957e-03 -5.537882e-01 ... -1.580318e+00\n",
            "    6.271386e-01  2.386168e-01]\n",
            "  [ 1.305613e+00 -1.466182e-01 -5.613658e-01 ... -2.030530e+00\n",
            "    1.165213e+00  5.844306e-01]]\n",
            "\n",
            " [[ 9.987506e-01 -2.872447e-02 -2.737818e-01 ... -4.229307e-02\n",
            "    2.569945e-01  2.112308e-01]\n",
            "  [ 1.218624e+00 -1.483652e-01 -3.057487e-01 ... -4.217256e-01\n",
            "    2.538453e-01  2.512406e-01]\n",
            "  [ 1.402226e+00 -2.253131e-01 -2.806468e-01 ... -3.892540e-01\n",
            "   -7.481108e-02  2.930543e-01]\n",
            "  ...\n",
            "  [ 8.338399e-01 -1.555462e-01 -1.605821e-01 ...  3.993726e-01\n",
            "    8.789377e-01 -6.928056e-02]\n",
            "  [ 7.350989e-01 -9.032520e-02 -1.021250e-01 ...  6.727401e-01\n",
            "    7.237755e-01  8.948482e-02]\n",
            "  [ 7.660746e-01 -4.404399e-02 -1.102332e-01 ...  6.077478e-01\n",
            "    6.154372e-01  2.512082e-01]]]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 9.265256e-01 -3.038519e-02 -2.757103e-01 ... -3.867692e-01\n",
            "   -8.428651e-02  3.149592e-02]\n",
            "  [ 9.514418e-01 -4.334551e-02 -2.584891e-01 ... -3.966365e-01\n",
            "   -1.056109e-01  6.744689e-02]\n",
            "  [ 9.836655e-01 -6.432124e-02 -2.241095e-01 ... -3.883913e-01\n",
            "   -1.009386e-01  6.434101e-02]\n",
            "  ...\n",
            "  [ 1.015150e+00 -4.330268e-01 -3.554990e-01 ... -5.281613e-01\n",
            "   -1.560355e-01  1.724524e-02]\n",
            "  [ 9.788111e-01 -4.102482e-01 -5.001350e-01 ... -5.336187e-01\n",
            "    8.856119e-02 -1.570109e-01]\n",
            "  [ 1.001810e+00 -3.960430e-01 -4.897565e-01 ... -7.647439e-01\n",
            "    3.163589e-01 -3.742592e-01]]\n",
            "\n",
            " [[ 8.213505e-01 -2.484623e-01 -2.216934e-01 ...  8.457912e-01\n",
            "    6.672695e-02 -7.659807e-01]\n",
            "  [ 7.991996e-01 -2.232599e-01 -2.045561e-01 ...  8.385992e-01\n",
            "   -2.486773e-01 -8.401374e-01]\n",
            "  [ 8.004623e-01 -1.790170e-01 -2.568719e-01 ...  8.132189e-01\n",
            "   -4.488040e-01 -8.572020e-01]\n",
            "  ...\n",
            "  [ 1.463170e+00 -5.515283e-01 -2.723974e-01 ... -9.962677e-01\n",
            "    9.452816e-01 -1.211067e-01]\n",
            "  [ 1.179223e+00 -5.472997e-01 -6.773376e-02 ... -1.011002e+00\n",
            "    4.431138e-01 -2.100397e-01]\n",
            "  [ 8.504963e-01 -4.900368e-01  1.378256e-01 ... -6.833800e-01\n",
            "   -4.617246e-01 -1.296910e-01]]\n",
            "\n",
            " [[ 7.713622e-01 -4.250499e-01 -5.327655e-02 ... -3.324763e-01\n",
            "   -1.093888e+00 -1.398256e-01]\n",
            "  [ 9.000949e-01 -4.375916e-01 -4.020727e-01 ... -3.165543e-01\n",
            "   -1.066005e+00 -1.855697e-01]\n",
            "  [ 8.681034e-01 -4.421595e-01 -5.197379e-01 ... -5.837689e-01\n",
            "   -5.695502e-01 -2.221543e-01]\n",
            "  ...\n",
            "  [ 9.188616e-01 -3.516799e-01 -7.253919e-02 ...  9.593065e-02\n",
            "   -2.102380e-02 -5.134232e-02]\n",
            "  [ 9.494752e-01 -2.675260e-01 -5.097549e-02 ...  9.070755e-02\n",
            "   -4.189301e-02 -7.887710e-02]\n",
            "  [ 9.578348e-01 -1.941603e-01 -2.892477e-02 ...  5.594314e-02\n",
            "   -1.024019e-01 -4.626822e-02]]]\n",
            "test\n",
            "[[[ 1.016458e+00 -1.260839e-01  8.734129e-02 ...  1.407080e-02\n",
            "    4.111184e-03 -1.208732e-02]\n",
            "  [ 1.016084e+00 -1.216043e-01  8.477703e-02 ...  1.228023e-02\n",
            "    1.004703e-03 -1.175323e-02]\n",
            "  [ 1.018847e+00 -1.188487e-01  8.260607e-02 ...  6.892319e-03\n",
            "    8.076805e-03 -1.152303e-02]\n",
            "  ...\n",
            "  [ 1.023488e+00 -1.430795e-01  8.043603e-02 ... -1.209368e-03\n",
            "   -2.519416e-02  2.647146e-02]\n",
            "  [ 1.024454e+00 -1.459939e-01  7.778891e-02 ...  1.109062e-02\n",
            "   -1.933155e-02  2.952505e-02]\n",
            "  [ 1.027167e+00 -1.475441e-01  7.410929e-02 ...  1.803845e-02\n",
            "   -7.570004e-03  2.225426e-02]]\n",
            "\n",
            " [[ 1.026736e+00 -1.508084e-01  7.640137e-02 ...  1.935230e-02\n",
            "   -6.373676e-04  1.483507e-02]\n",
            "  [ 1.023176e+00 -1.495573e-01  8.244215e-02 ...  2.444080e-02\n",
            "   -2.161241e-03  1.945103e-02]\n",
            "  [ 1.021860e+00 -1.441922e-01  8.154024e-02 ...  2.405094e-02\n",
            "   -3.777881e-03  2.030669e-02]\n",
            "  ...\n",
            "  [ 1.024099e+00 -1.402220e-01  7.307697e-02 ...  1.079074e-02\n",
            "    2.682376e-03 -1.518554e-02]\n",
            "  [ 1.025135e+00 -1.352114e-01  7.599545e-02 ...  9.806578e-03\n",
            "   -1.425158e-02 -1.809143e-02]\n",
            "  [ 1.027036e+00 -1.379930e-01  7.555214e-02 ...  1.029893e-02\n",
            "   -3.099960e-02 -2.062724e-02]]\n",
            "\n",
            " [[ 1.019400e+00 -1.285880e-01  7.872325e-02 ...  3.297174e-03\n",
            "    2.883959e-03  3.028906e-03]\n",
            "  [ 1.019465e+00 -1.297452e-01  7.702548e-02 ... -1.468074e-03\n",
            "    2.167184e-03  7.346918e-04]\n",
            "  [ 1.020643e+00 -1.289535e-01  7.528321e-02 ... -6.687127e-03\n",
            "    8.140757e-04 -4.684179e-05]\n",
            "  ...\n",
            "  [ 1.022221e+00 -1.317043e-01  7.333959e-02 ...  1.421975e-03\n",
            "    2.820155e-03 -3.250224e-03]\n",
            "  [ 1.022120e+00 -1.311004e-01  7.547599e-02 ... -2.471821e-03\n",
            "    3.764711e-03  2.388124e-03]\n",
            "  [ 1.022180e+00 -1.307122e-01  7.633473e-02 ... -4.281772e-03\n",
            "    3.828749e-03  6.101551e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 7.876250e-01 -2.194825e-01 -1.220350e-01 ...  7.990285e-01\n",
            "    2.277792e-01 -1.852965e-01]\n",
            "  [ 7.404105e-01 -2.406550e-01 -1.185273e-01 ...  9.143494e-01\n",
            "    1.507831e-01 -1.637415e-01]\n",
            "  [ 7.079936e-01 -2.170710e-01 -1.547061e-01 ...  7.509549e-01\n",
            "    8.297923e-02 -1.302788e-01]\n",
            "  ...\n",
            "  [ 1.479803e+00 -2.033096e-01 -3.752810e-01 ...  5.698074e-01\n",
            "   -3.460038e-01  2.493418e-01]\n",
            "  [ 1.495555e+00 -2.270006e-01 -4.384375e-01 ...  5.565363e-01\n",
            "   -6.374220e-01  2.889715e-01]\n",
            "  [ 1.410861e+00 -2.635673e-01 -5.477404e-01 ...  4.757040e-01\n",
            "   -8.960849e-01  3.947928e-01]]\n",
            "\n",
            " [[ 1.363551e+00 -3.962879e-01 -6.292355e-01 ...  4.385332e-01\n",
            "   -3.742540e-01  4.646355e-01]\n",
            "  [ 1.241762e+00 -5.238760e-01 -5.789589e-01 ...  6.528946e-01\n",
            "    2.229137e-01  5.012031e-01]\n",
            "  [ 1.050525e+00 -5.556186e-01 -4.160527e-01 ...  1.021674e+00\n",
            "    3.801760e-01  4.306796e-01]\n",
            "  ...\n",
            "  [ 9.393409e-01 -1.334399e-01 -3.101494e-01 ... -1.732192e-01\n",
            "   -1.554326e-01 -4.977084e-02]\n",
            "  [ 9.618982e-01 -9.423238e-02 -3.196609e-01 ... -2.458214e-01\n",
            "   -4.034872e-02 -3.446930e-02]\n",
            "  [ 9.348139e-01 -5.825780e-02 -3.038431e-01 ... -3.598074e-01\n",
            "   -3.765012e-02 -2.113494e-02]]\n",
            "\n",
            " [[ 1.037668e+00 -3.971532e-01 -3.940817e-01 ... -8.444065e-01\n",
            "    3.994681e-01 -5.342947e-01]\n",
            "  [ 8.780725e-01 -2.848634e-01 -3.151097e-01 ... -6.438182e-01\n",
            "    2.690953e-01 -7.094171e-01]\n",
            "  [ 8.963897e-01 -2.635297e-01 -2.139040e-01 ... -5.957706e-01\n",
            "    2.522084e-01 -7.025197e-01]\n",
            "  ...\n",
            "  [ 1.156389e+00 -2.283478e-01 -3.512052e-03 ... -4.749118e-01\n",
            "    2.486630e-02  2.332489e-01]\n",
            "  [ 1.243857e+00 -2.583220e-01 -1.117857e-01 ... -5.493259e-01\n",
            "   -1.060269e-01  3.001525e-01]\n",
            "  [ 1.323546e+00 -3.472416e-01 -2.760682e-01 ... -6.220308e-01\n",
            "   -2.043685e-01  4.318673e-01]]]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[[[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " [[ 1.017682e+00 -1.334039e-01  9.515180e-02 ... -3.751574e-02\n",
            "   -1.288632e-02 -8.727416e-04]\n",
            "  [ 1.018149e+00 -1.343639e-01  9.541539e-02 ... -3.309700e-02\n",
            "   -1.691822e-02 -5.481970e-03]\n",
            "  [ 1.019854e+00 -1.352028e-01  8.827355e-02 ... -3.036013e-02\n",
            "   -1.618518e-02 -4.678230e-03]\n",
            "  ...\n",
            "  [ 1.019916e+00 -1.319863e-01  8.576054e-02 ... -2.015042e-02\n",
            "    1.401018e-03 -8.408470e-03]\n",
            "  [ 1.019602e+00 -1.345073e-01  8.327454e-02 ... -1.695977e-02\n",
            "    4.472376e-04 -1.115822e-02]\n",
            "  [ 1.020735e+00 -1.333157e-01  8.140418e-02 ... -7.120059e-03\n",
            "    1.950985e-03 -1.298664e-02]]\n",
            "\n",
            " [[ 1.019952e+00 -1.287306e-01  8.084140e-02 ... -1.942932e-02\n",
            "   -8.612378e-03 -1.574010e-03]\n",
            "  [ 1.019616e+00 -1.278461e-01  7.912684e-02 ... -1.909099e-02\n",
            "   -8.146719e-03  2.007077e-04]\n",
            "  [ 1.020933e+00 -1.282300e-01  7.829138e-02 ... -1.481631e-02\n",
            "   -5.376620e-03 -9.700938e-04]\n",
            "  ...\n",
            "  [ 1.019425e+00 -1.245585e-01  8.132876e-02 ...  1.145144e-02\n",
            "   -5.571703e-03 -4.491357e-03]\n",
            "  [ 1.018896e+00 -1.214556e-01  8.539719e-02 ...  1.268365e-02\n",
            "    3.417937e-03 -3.441367e-03]\n",
            "  [ 1.016787e+00 -1.234940e-01  8.881566e-02 ...  1.560483e-02\n",
            "    1.079681e-02 -1.008158e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 9.265256e-01 -3.038519e-02 -2.757103e-01 ... -3.867692e-01\n",
            "   -8.428651e-02  3.149592e-02]\n",
            "  [ 9.514418e-01 -4.334551e-02 -2.584891e-01 ... -3.966365e-01\n",
            "   -1.056109e-01  6.744689e-02]\n",
            "  [ 9.836655e-01 -6.432124e-02 -2.241095e-01 ... -3.883913e-01\n",
            "   -1.009386e-01  6.434101e-02]\n",
            "  ...\n",
            "  [ 1.015150e+00 -4.330268e-01 -3.554990e-01 ... -5.281613e-01\n",
            "   -1.560355e-01  1.724524e-02]\n",
            "  [ 9.788111e-01 -4.102482e-01 -5.001350e-01 ... -5.336187e-01\n",
            "    8.856119e-02 -1.570109e-01]\n",
            "  [ 1.001810e+00 -3.960430e-01 -4.897565e-01 ... -7.647439e-01\n",
            "    3.163589e-01 -3.742592e-01]]\n",
            "\n",
            " [[ 8.213505e-01 -2.484623e-01 -2.216934e-01 ...  8.457912e-01\n",
            "    6.672695e-02 -7.659807e-01]\n",
            "  [ 7.991996e-01 -2.232599e-01 -2.045561e-01 ...  8.385992e-01\n",
            "   -2.486773e-01 -8.401374e-01]\n",
            "  [ 8.004623e-01 -1.790170e-01 -2.568719e-01 ...  8.132189e-01\n",
            "   -4.488040e-01 -8.572020e-01]\n",
            "  ...\n",
            "  [ 1.463170e+00 -5.515283e-01 -2.723974e-01 ... -9.962677e-01\n",
            "    9.452816e-01 -1.211067e-01]\n",
            "  [ 1.179223e+00 -5.472997e-01 -6.773376e-02 ... -1.011002e+00\n",
            "    4.431138e-01 -2.100397e-01]\n",
            "  [ 8.504963e-01 -4.900368e-01  1.378256e-01 ... -6.833800e-01\n",
            "   -4.617246e-01 -1.296910e-01]]\n",
            "\n",
            " [[ 1.037668e+00 -3.971532e-01 -3.940817e-01 ... -8.444065e-01\n",
            "    3.994681e-01 -5.342947e-01]\n",
            "  [ 8.780725e-01 -2.848634e-01 -3.151097e-01 ... -6.438182e-01\n",
            "    2.690953e-01 -7.094171e-01]\n",
            "  [ 8.963897e-01 -2.635297e-01 -2.139040e-01 ... -5.957706e-01\n",
            "    2.522084e-01 -7.025197e-01]\n",
            "  ...\n",
            "  [ 1.156389e+00 -2.283478e-01 -3.512052e-03 ... -4.749118e-01\n",
            "    2.486630e-02  2.332489e-01]\n",
            "  [ 1.243857e+00 -2.583220e-01 -1.117857e-01 ... -5.493259e-01\n",
            "   -1.060269e-01  3.001525e-01]\n",
            "  [ 1.323546e+00 -3.472416e-01 -2.760682e-01 ... -6.220308e-01\n",
            "   -2.043685e-01  4.318673e-01]]]\n",
            "test\n",
            "[[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.008712e+00 -2.528722e-01 -1.013614e-02 ...  2.910554e-02\n",
            "    9.385273e-02 -1.039089e-01]\n",
            "  [ 1.009520e+00 -2.513164e-01 -1.113510e-02 ...  2.740325e-02\n",
            "    9.551107e-02 -1.054117e-01]\n",
            "  [ 1.010496e+00 -2.514933e-01 -8.086015e-03 ...  2.151230e-02\n",
            "    9.228726e-02 -1.062399e-01]\n",
            "  ...\n",
            "  [ 1.007193e+00 -2.478090e-01 -2.417474e-02 ...  1.692982e-02\n",
            "    1.321372e-02 -1.269865e-02]\n",
            "  [ 1.008487e+00 -2.492657e-01 -2.160812e-02 ...  2.150799e-02\n",
            "    1.411459e-02 -1.375677e-02]\n",
            "  [ 1.009021e+00 -2.516812e-01 -2.433908e-02 ...  2.563674e-02\n",
            "    1.502719e-02 -1.758165e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1.052938e+00  9.566184e-02 -2.245060e-01 ...  4.389320e-02\n",
            "   -1.462479e-01 -1.514158e-01]\n",
            "  [ 1.055713e+00  1.078428e-01 -2.364650e-01 ...  3.407797e-02\n",
            "   -1.871376e-01 -9.283012e-02]\n",
            "  [ 1.109037e+00  2.392364e-02 -2.599991e-01 ... -1.952540e-02\n",
            "   -2.739348e-01 -5.980959e-03]\n",
            "  ...\n",
            "  [ 7.447761e-01 -2.273388e-01 -2.606236e-01 ...  4.901740e-01\n",
            "   -8.140118e-02 -5.511131e-01]\n",
            "  [ 7.366306e-01 -2.465245e-01 -2.555008e-01 ...  4.895633e-01\n",
            "   -3.933115e-02 -5.409352e-01]\n",
            "  [ 7.703742e-01 -2.688468e-01 -2.347403e-01 ...  5.216781e-01\n",
            "    1.193573e-01 -6.028448e-01]]\n",
            "\n",
            " [[ 7.429507e-01 -1.494530e-01 -1.895648e-01 ...  1.009856e+00\n",
            "   -2.262452e-01  3.917866e-03]\n",
            "  [ 8.262587e-01 -1.881017e-01 -2.216621e-01 ...  7.792477e-01\n",
            "   -1.099573e-01  4.021547e-02]\n",
            "  [ 8.894542e-01 -2.200253e-01 -1.933017e-01 ...  6.823191e-01\n",
            "    7.832972e-02  1.697701e-02]\n",
            "  ...\n",
            "  [ 8.665250e-01 -3.955218e-01 -2.356994e-01 ...  6.502768e-01\n",
            "    6.464923e-02  3.613880e-01]\n",
            "  [ 7.689960e-01 -3.820558e-01 -2.328383e-01 ...  6.661007e-01\n",
            "    3.888121e-02  3.487162e-01]\n",
            "  [ 8.988848e-01 -3.796649e-01 -2.698744e-01 ...  6.452335e-01\n",
            "    1.585737e-01  3.258727e-01]]\n",
            "\n",
            " [[ 7.713622e-01 -4.250499e-01 -5.327655e-02 ... -3.324763e-01\n",
            "   -1.093888e+00 -1.398256e-01]\n",
            "  [ 9.000949e-01 -4.375916e-01 -4.020727e-01 ... -3.165543e-01\n",
            "   -1.066005e+00 -1.855697e-01]\n",
            "  [ 8.681034e-01 -4.421595e-01 -5.197379e-01 ... -5.837689e-01\n",
            "   -5.695502e-01 -2.221543e-01]\n",
            "  ...\n",
            "  [ 9.188616e-01 -3.516799e-01 -7.253919e-02 ...  9.593065e-02\n",
            "   -2.102380e-02 -5.134232e-02]\n",
            "  [ 9.494752e-01 -2.675260e-01 -5.097549e-02 ...  9.070755e-02\n",
            "   -4.189301e-02 -7.887710e-02]\n",
            "  [ 9.578348e-01 -1.941603e-01 -2.892477e-02 ...  5.594314e-02\n",
            "   -1.024019e-01 -4.626822e-02]]]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 8.213505e-01 -2.484623e-01 -2.216934e-01 ...  8.457912e-01\n",
            "    6.672695e-02 -7.659807e-01]\n",
            "  [ 7.991996e-01 -2.232599e-01 -2.045561e-01 ...  8.385992e-01\n",
            "   -2.486773e-01 -8.401374e-01]\n",
            "  [ 8.004623e-01 -1.790170e-01 -2.568719e-01 ...  8.132189e-01\n",
            "   -4.488040e-01 -8.572020e-01]\n",
            "  ...\n",
            "  [ 1.463170e+00 -5.515283e-01 -2.723974e-01 ... -9.962677e-01\n",
            "    9.452816e-01 -1.211067e-01]\n",
            "  [ 1.179223e+00 -5.472997e-01 -6.773376e-02 ... -1.011002e+00\n",
            "    4.431138e-01 -2.100397e-01]\n",
            "  [ 8.504963e-01 -4.900368e-01  1.378256e-01 ... -6.833800e-01\n",
            "   -4.617246e-01 -1.296910e-01]]\n",
            "\n",
            " [[ 1.037668e+00 -3.971532e-01 -3.940817e-01 ... -8.444065e-01\n",
            "    3.994681e-01 -5.342947e-01]\n",
            "  [ 8.780725e-01 -2.848634e-01 -3.151097e-01 ... -6.438182e-01\n",
            "    2.690953e-01 -7.094171e-01]\n",
            "  [ 8.963897e-01 -2.635297e-01 -2.139040e-01 ... -5.957706e-01\n",
            "    2.522084e-01 -7.025197e-01]\n",
            "  ...\n",
            "  [ 1.156389e+00 -2.283478e-01 -3.512052e-03 ... -4.749118e-01\n",
            "    2.486630e-02  2.332489e-01]\n",
            "  [ 1.243857e+00 -2.583220e-01 -1.117857e-01 ... -5.493259e-01\n",
            "   -1.060269e-01  3.001525e-01]\n",
            "  [ 1.323546e+00 -3.472416e-01 -2.760682e-01 ... -6.220308e-01\n",
            "   -2.043685e-01  4.318673e-01]]\n",
            "\n",
            " [[ 7.713622e-01 -4.250499e-01 -5.327655e-02 ... -3.324763e-01\n",
            "   -1.093888e+00 -1.398256e-01]\n",
            "  [ 9.000949e-01 -4.375916e-01 -4.020727e-01 ... -3.165543e-01\n",
            "   -1.066005e+00 -1.855697e-01]\n",
            "  [ 8.681034e-01 -4.421595e-01 -5.197379e-01 ... -5.837689e-01\n",
            "   -5.695502e-01 -2.221543e-01]\n",
            "  ...\n",
            "  [ 9.188616e-01 -3.516799e-01 -7.253919e-02 ...  9.593065e-02\n",
            "   -2.102380e-02 -5.134232e-02]\n",
            "  [ 9.494752e-01 -2.675260e-01 -5.097549e-02 ...  9.070755e-02\n",
            "   -4.189301e-02 -7.887710e-02]\n",
            "  [ 9.578348e-01 -1.941603e-01 -2.892477e-02 ...  5.594314e-02\n",
            "   -1.024019e-01 -4.626822e-02]]]\n",
            "test\n",
            "[[[ 1.025473e+00 -1.416741e-01  7.453064e-02 ...  8.530243e-03\n",
            "   -3.243686e-02 -2.166662e-02]\n",
            "  [ 1.019491e+00 -1.458623e-01  7.705920e-02 ...  1.741838e-02\n",
            "   -2.676116e-02 -1.558095e-02]\n",
            "  [ 1.015506e+00 -1.511128e-01  7.864804e-02 ...  2.546787e-02\n",
            "   -2.694071e-02 -1.280395e-02]\n",
            "  ...\n",
            "  [ 1.021387e+00 -1.296054e-01  8.289593e-02 ...  8.864319e-03\n",
            "   -5.567113e-03  6.443686e-03]\n",
            "  [ 1.020704e+00 -1.297571e-01  8.223304e-02 ...  3.119118e-03\n",
            "   -5.993914e-03  6.636407e-03]\n",
            "  [ 1.019645e+00 -1.292091e-01  7.891713e-02 ...  2.616139e-05\n",
            "   -1.125754e-03  5.391502e-03]]\n",
            "\n",
            " [[ 1.011234e+00 -2.511435e-01 -1.850821e-02 ... -1.538794e-03\n",
            "    3.397536e-03 -1.220739e-03]\n",
            "  [ 1.013388e+00 -2.538186e-01 -2.259876e-02 ... -1.027360e-03\n",
            "    2.217334e-03 -2.409992e-03]\n",
            "  [ 1.012280e+00 -2.510822e-01 -2.704317e-02 ... -4.859355e-04\n",
            "    5.402636e-04 -6.515109e-03]\n",
            "  ...\n",
            "  [ 1.013301e+00 -2.395051e-01 -1.678197e-02 ...  7.828966e-04\n",
            "   -5.460447e-03  5.747899e-04]\n",
            "  [ 1.011795e+00 -2.387725e-01 -1.663689e-02 ...  1.473151e-03\n",
            "   -5.539423e-03  4.492647e-03]\n",
            "  [ 1.012324e+00 -2.438231e-01 -1.617449e-02 ...  2.930485e-03\n",
            "   -4.445612e-04 -3.664609e-04]]\n",
            "\n",
            " [[ 7.785759e-01  4.311469e-01  4.488391e-01 ... -1.905581e-02\n",
            "   -3.148347e-02  5.531711e-02]\n",
            "  [ 7.796643e-01  4.323949e-01  4.491236e-01 ... -1.944289e-02\n",
            "   -3.276920e-02  5.379975e-02]\n",
            "  [ 7.811115e-01  4.320012e-01  4.505731e-01 ... -2.021983e-02\n",
            "   -3.224512e-02  5.475307e-02]\n",
            "  ...\n",
            "  [ 7.792646e-01  4.347350e-01  4.530148e-01 ... -1.106532e-02\n",
            "   -3.953641e-03  1.595635e-02]\n",
            "  [ 7.795026e-01  4.327924e-01  4.539103e-01 ... -1.111716e-02\n",
            "   -5.983801e-03  1.742971e-02]\n",
            "  [ 7.788668e-01  4.359845e-01  4.544497e-01 ... -1.088137e-02\n",
            "   -1.042185e-02  1.588613e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 9.122950e-01 -2.110211e-02 -1.450757e-01 ...  6.734168e-01\n",
            "   -1.491621e-01 -1.169979e-03]\n",
            "  [ 8.900624e-01 -4.379447e-02 -1.417169e-01 ...  7.512018e-01\n",
            "    8.650368e-02 -8.865144e-02]\n",
            "  [ 8.639025e-01 -3.136713e-02 -1.359576e-01 ...  8.644957e-01\n",
            "    2.445304e-01 -1.291139e-01]\n",
            "  ...\n",
            "  [ 8.169024e-01 -9.380456e-03 -9.355127e-02 ...  3.027431e-01\n",
            "    7.420180e-02  3.328322e-02]\n",
            "  [ 8.728354e-01  1.033523e-02 -1.128897e-01 ...  2.529718e-01\n",
            "    1.369205e-01  3.280921e-02]\n",
            "  [ 8.726345e-01 -2.583858e-03 -1.157404e-01 ...  1.744924e-01\n",
            "    4.346355e-01 -2.464136e-02]]\n",
            "\n",
            " [[ 9.484417e-01 -2.354725e-01 -6.478156e-03 ...  5.336086e-01\n",
            "   -2.345559e-01 -2.498904e-02]\n",
            "  [ 1.025033e+00 -2.619295e-01 -3.463738e-02 ...  6.925418e-01\n",
            "   -4.921769e-01 -7.285356e-03]\n",
            "  [ 1.196099e+00 -2.531810e-01 -9.070212e-02 ...  9.343445e-01\n",
            "   -8.949937e-01  1.894036e-02]\n",
            "  ...\n",
            "  [ 9.091869e-01 -1.996193e-01 -2.112545e-01 ...  8.527635e-01\n",
            "    4.720681e-01 -1.975862e-01]\n",
            "  [ 8.543253e-01 -2.056370e-01 -1.768381e-01 ...  7.765030e-01\n",
            "    4.459471e-01 -2.450961e-01]\n",
            "  [ 8.093597e-01 -2.066582e-01 -1.318524e-01 ...  7.433143e-01\n",
            "    3.780495e-01 -1.964940e-01]]\n",
            "\n",
            " [[ 9.265256e-01 -3.038519e-02 -2.757103e-01 ... -3.867692e-01\n",
            "   -8.428651e-02  3.149592e-02]\n",
            "  [ 9.514418e-01 -4.334551e-02 -2.584891e-01 ... -3.966365e-01\n",
            "   -1.056109e-01  6.744689e-02]\n",
            "  [ 9.836655e-01 -6.432124e-02 -2.241095e-01 ... -3.883913e-01\n",
            "   -1.009386e-01  6.434101e-02]\n",
            "  ...\n",
            "  [ 1.015150e+00 -4.330268e-01 -3.554990e-01 ... -5.281613e-01\n",
            "   -1.560355e-01  1.724524e-02]\n",
            "  [ 9.788111e-01 -4.102482e-01 -5.001350e-01 ... -5.336187e-01\n",
            "    8.856119e-02 -1.570109e-01]\n",
            "  [ 1.001810e+00 -3.960430e-01 -4.897565e-01 ... -7.647439e-01\n",
            "    3.163589e-01 -3.742592e-01]]]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[[[ 1.012817e+00 -1.232167e-01  1.029341e-01 ...  3.019122e-02\n",
            "    6.601362e-02  2.285864e-02]\n",
            "  [ 1.022833e+00 -1.268756e-01  1.056872e-01 ...  4.371071e-02\n",
            "    4.269897e-02  1.031572e-02]\n",
            "  [ 1.022028e+00 -1.240037e-01  1.021025e-01 ...  3.568780e-02\n",
            "    7.485018e-02  1.324969e-02]\n",
            "  ...\n",
            "  [ 1.018445e+00 -1.240696e-01  1.003852e-01 ...  3.985177e-02\n",
            "    1.909445e-03 -2.170124e-03]\n",
            "  [ 1.019372e+00 -1.227451e-01  9.987355e-02 ...  3.744932e-02\n",
            "   -7.982483e-05 -5.642633e-03]\n",
            "  [ 1.021171e+00 -1.213260e-01  9.498741e-02 ...  2.881781e-02\n",
            "   -3.771800e-05 -1.446006e-03]]\n",
            "\n",
            " [[ 1.018851e+00 -1.239760e-01  9.792958e-02 ...  1.711106e-02\n",
            "    6.122797e-03  1.226815e-02]\n",
            "  [ 1.022380e+00 -1.268078e-01  9.935086e-02 ...  2.417851e-02\n",
            "    9.710357e-03  1.614958e-02]\n",
            "  [ 1.020781e+00 -1.277862e-01  9.811381e-02 ...  3.022889e-02\n",
            "    1.032192e-02  1.589471e-02]\n",
            "  ...\n",
            "  [ 1.014788e+00 -1.290268e-01  9.353520e-02 ... -3.474078e-02\n",
            "   -8.694754e-03  5.044730e-03]\n",
            "  [ 1.016499e+00 -1.264244e-01  8.903516e-02 ... -3.797305e-02\n",
            "   -1.165249e-02 -4.424329e-03]\n",
            "  [ 1.017849e+00 -1.305193e-01  9.061235e-02 ... -3.864973e-02\n",
            "   -9.440197e-03 -2.797817e-03]]\n",
            "\n",
            " [[ 1.023127e+00 -1.200157e-01  9.111667e-02 ...  2.618877e-02\n",
            "   -2.383410e-04  2.158897e-03]\n",
            "  [ 1.021882e+00 -1.214994e-01  9.267560e-02 ...  2.165149e-02\n",
            "   -4.275982e-04 -2.724752e-04]\n",
            "  [ 1.019178e+00 -1.228407e-01  9.606378e-02 ...  1.455062e-02\n",
            "    7.611350e-04  2.630986e-03]\n",
            "  ...\n",
            "  [ 1.021041e+00 -1.308757e-01  8.301135e-02 ... -2.090983e-02\n",
            "   -1.005391e-02 -5.566286e-03]\n",
            "  [ 1.022935e+00 -1.312099e-01  8.233391e-02 ... -2.211369e-02\n",
            "   -9.717281e-03 -3.701625e-03]\n",
            "  [ 1.022019e+00 -1.301826e-01  8.148748e-02 ... -2.023537e-02\n",
            "   -8.831462e-03 -2.644745e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 9.265256e-01 -3.038519e-02 -2.757103e-01 ... -3.867692e-01\n",
            "   -8.428651e-02  3.149592e-02]\n",
            "  [ 9.514418e-01 -4.334551e-02 -2.584891e-01 ... -3.966365e-01\n",
            "   -1.056109e-01  6.744689e-02]\n",
            "  [ 9.836655e-01 -6.432124e-02 -2.241095e-01 ... -3.883913e-01\n",
            "   -1.009386e-01  6.434101e-02]\n",
            "  ...\n",
            "  [ 1.015150e+00 -4.330268e-01 -3.554990e-01 ... -5.281613e-01\n",
            "   -1.560355e-01  1.724524e-02]\n",
            "  [ 9.788111e-01 -4.102482e-01 -5.001350e-01 ... -5.336187e-01\n",
            "    8.856119e-02 -1.570109e-01]\n",
            "  [ 1.001810e+00 -3.960430e-01 -4.897565e-01 ... -7.647439e-01\n",
            "    3.163589e-01 -3.742592e-01]]\n",
            "\n",
            " [[ 1.037668e+00 -3.971532e-01 -3.940817e-01 ... -8.444065e-01\n",
            "    3.994681e-01 -5.342947e-01]\n",
            "  [ 8.780725e-01 -2.848634e-01 -3.151097e-01 ... -6.438182e-01\n",
            "    2.690953e-01 -7.094171e-01]\n",
            "  [ 8.963897e-01 -2.635297e-01 -2.139040e-01 ... -5.957706e-01\n",
            "    2.522084e-01 -7.025197e-01]\n",
            "  ...\n",
            "  [ 1.156389e+00 -2.283478e-01 -3.512052e-03 ... -4.749118e-01\n",
            "    2.486630e-02  2.332489e-01]\n",
            "  [ 1.243857e+00 -2.583220e-01 -1.117857e-01 ... -5.493259e-01\n",
            "   -1.060269e-01  3.001525e-01]\n",
            "  [ 1.323546e+00 -3.472416e-01 -2.760682e-01 ... -6.220308e-01\n",
            "   -2.043685e-01  4.318673e-01]]\n",
            "\n",
            " [[ 7.713622e-01 -4.250499e-01 -5.327655e-02 ... -3.324763e-01\n",
            "   -1.093888e+00 -1.398256e-01]\n",
            "  [ 9.000949e-01 -4.375916e-01 -4.020727e-01 ... -3.165543e-01\n",
            "   -1.066005e+00 -1.855697e-01]\n",
            "  [ 8.681034e-01 -4.421595e-01 -5.197379e-01 ... -5.837689e-01\n",
            "   -5.695502e-01 -2.221543e-01]\n",
            "  ...\n",
            "  [ 9.188616e-01 -3.516799e-01 -7.253919e-02 ...  9.593065e-02\n",
            "   -2.102380e-02 -5.134232e-02]\n",
            "  [ 9.494752e-01 -2.675260e-01 -5.097549e-02 ...  9.070755e-02\n",
            "   -4.189301e-02 -7.887710e-02]\n",
            "  [ 9.578348e-01 -1.941603e-01 -2.892477e-02 ...  5.594314e-02\n",
            "   -1.024019e-01 -4.626822e-02]]]\n",
            "test\n",
            "[[[ 1.017682e+00 -1.334039e-01  9.515180e-02 ... -3.751574e-02\n",
            "   -1.288632e-02 -8.727416e-04]\n",
            "  [ 1.018149e+00 -1.343639e-01  9.541539e-02 ... -3.309700e-02\n",
            "   -1.691822e-02 -5.481970e-03]\n",
            "  [ 1.019854e+00 -1.352028e-01  8.827355e-02 ... -3.036013e-02\n",
            "   -1.618518e-02 -4.678230e-03]\n",
            "  ...\n",
            "  [ 1.019916e+00 -1.319863e-01  8.576054e-02 ... -2.015042e-02\n",
            "    1.401018e-03 -8.408470e-03]\n",
            "  [ 1.019602e+00 -1.345073e-01  8.327454e-02 ... -1.695977e-02\n",
            "    4.472376e-04 -1.115822e-02]\n",
            "  [ 1.020735e+00 -1.333157e-01  8.140418e-02 ... -7.120059e-03\n",
            "    1.950985e-03 -1.298664e-02]]\n",
            "\n",
            " [[ 1.023996e+00 -1.174678e-01  8.833936e-02 ...  1.216850e-02\n",
            "   -6.969374e-03  1.717108e-02]\n",
            "  [ 1.024485e+00 -1.183863e-01  8.184867e-02 ...  1.188859e-02\n",
            "   -1.483408e-03  8.784918e-03]\n",
            "  [ 1.025120e+00 -1.182194e-01  7.650382e-02 ...  1.098272e-02\n",
            "    8.025620e-03  9.499296e-03]\n",
            "  ...\n",
            "  [ 1.019584e+00 -1.345625e-01  7.407130e-02 ... -6.641120e-03\n",
            "    1.058230e-02 -1.374750e-02]\n",
            "  [ 1.018790e+00 -1.370743e-01  7.404372e-02 ... -4.793323e-03\n",
            "    1.388685e-02 -1.119056e-02]\n",
            "  [ 1.019997e+00 -1.351569e-01  7.339988e-02 ... -5.356274e-03\n",
            "    1.756218e-02 -7.536175e-03]]\n",
            "\n",
            " [[ 1.019289e+00 -1.343615e-01  7.531443e-02 ... -9.675544e-03\n",
            "    1.496756e-02 -6.899270e-03]\n",
            "  [ 1.019233e+00 -1.368448e-01  7.591377e-02 ... -1.382584e-02\n",
            "    9.419482e-03 -6.752819e-03]\n",
            "  [ 1.019822e+00 -1.378271e-01  7.628165e-02 ... -9.792307e-03\n",
            "    6.544515e-03 -2.038098e-03]\n",
            "  ...\n",
            "  [ 1.020917e+00 -1.361446e-01  8.064469e-02 ... -1.683185e-03\n",
            "    4.250539e-03  5.631682e-03]\n",
            "  [ 1.018978e+00 -1.301731e-01  8.181490e-02 ... -2.887422e-04\n",
            "   -1.425837e-03  5.660710e-03]\n",
            "  [ 1.018788e+00 -1.273727e-01  7.943561e-02 ... -3.649420e-03\n",
            "   -2.730476e-03  5.812177e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 9.859140e-01 -4.054208e-01 -2.534432e-01 ...  7.742022e-01\n",
            "    2.165489e-01  2.456697e-01]\n",
            "  [ 9.301742e-01 -3.506467e-01 -2.277658e-01 ...  7.761254e-01\n",
            "    2.114868e-01  1.107333e-01]\n",
            "  [ 9.198548e-01 -2.913863e-01 -2.334882e-01 ...  7.367724e-01\n",
            "    2.626904e-01 -3.942923e-02]\n",
            "  ...\n",
            "  [ 1.044689e+00  1.979401e-02 -2.881265e-01 ...  1.335670e-01\n",
            "   -4.363882e-01 -1.241342e-01]\n",
            "  [ 1.113898e+00  1.797065e-02 -2.973864e-01 ... -2.811494e-02\n",
            "   -2.963482e-01 -1.507420e-01]\n",
            "  [ 1.103151e+00  1.706202e-03 -2.735142e-01 ... -1.172493e-01\n",
            "   -1.595591e-01 -1.502842e-01]]\n",
            "\n",
            " [[ 1.069760e+00 -2.128328e-02 -2.473921e-01 ... -2.106883e-01\n",
            "   -8.991108e-02 -1.461478e-01]\n",
            "  [ 1.085756e+00 -4.631315e-02 -2.436013e-01 ... -2.065051e-01\n",
            "   -1.776506e-01 -1.019857e-01]\n",
            "  [ 1.144664e+00 -1.678209e-01 -2.924359e-01 ... -1.233800e-01\n",
            "   -2.146743e-01  5.906554e-03]\n",
            "  ...\n",
            "  [ 8.228118e-01 -2.478404e-01 -3.306354e-01 ...  6.958538e-01\n",
            "    1.928357e-01 -6.075867e-01]\n",
            "  [ 8.137139e-01 -2.576758e-01 -2.547939e-01 ...  7.432665e-01\n",
            "    2.530518e-01 -6.256409e-01]\n",
            "  [ 7.673086e-01 -2.505263e-01 -2.294359e-01 ...  7.779873e-01\n",
            "    2.242028e-01 -7.041832e-01]]\n",
            "\n",
            " [[ 8.213505e-01 -2.484623e-01 -2.216934e-01 ...  8.457912e-01\n",
            "    6.672695e-02 -7.659807e-01]\n",
            "  [ 7.991996e-01 -2.232599e-01 -2.045561e-01 ...  8.385992e-01\n",
            "   -2.486773e-01 -8.401374e-01]\n",
            "  [ 8.004623e-01 -1.790170e-01 -2.568719e-01 ...  8.132189e-01\n",
            "   -4.488040e-01 -8.572020e-01]\n",
            "  ...\n",
            "  [ 1.463170e+00 -5.515283e-01 -2.723974e-01 ... -9.962677e-01\n",
            "    9.452816e-01 -1.211067e-01]\n",
            "  [ 1.179223e+00 -5.472997e-01 -6.773376e-02 ... -1.011002e+00\n",
            "    4.431138e-01 -2.100397e-01]\n",
            "  [ 8.504963e-01 -4.900368e-01  1.378256e-01 ... -6.833800e-01\n",
            "   -4.617246e-01 -1.296910e-01]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "i=1\n",
        "b=[]\n",
        "while i<=100:\n",
        "  a.append(i)\n",
        "  if i%2==0:\n",
        "    b.append(True)\n",
        "  else:\n",
        "    b.append(False)\n",
        "  i+=1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(a, b):\n",
        "  print(\"-------------------------------------------------------------------------------s\")\n",
        "  print(\"train\")\n",
        "  print(np.array(a)[train.astype(int)])\n",
        "  print(np.array(b)[train.astype(int)])\n",
        "  print(\"test\")\n",
        "  print(np.array(a)[test.astype(int)])\n",
        "  print(np.array(b)[test.astype(int)])"
      ],
      "metadata": {
        "id": "dkNJQPcRfvDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8508c206-06c7-4d4b-9caf-5264ade6e6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
            "[False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[  1   2   3   4   5   7   8   9  10  11  14  15  16  17  18  19  20  21\n",
            "  22  23  24  25  29  30  31  32  33  34  35  37  38  39  40  41  42  43\n",
            "  45  46  47  48  51  53  54  56  58  59  61  63  64  65  67  68  69  70\n",
            "  71  72  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90\n",
            "  92  93  94  95  97  98  99 100]\n",
            "[False  True False  True False False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False False  True\n",
            " False  True False  True False False  True False  True False  True False\n",
            " False  True False  True False False  True  True  True False False False\n",
            "  True False False  True False  True False  True False  True False  True\n",
            " False  True False False  True  True False  True False  True False  True\n",
            "  True False  True False False  True False  True]\n",
            "test\n",
            "[ 6 12 13 26 27 28 36 44 49 50 52 55 57 60 62 66 80 83 91 96]\n",
            "[ True  True False  True False  True  True  True False  True  True False\n",
            " False  True  True  True  True False False  True]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[  1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  19  20\n",
            "  21  22  23  25  26  27  28  31  32  35  36  37  38  39  40  41  42  43\n",
            "  44  45  46  48  49  50  51  52  54  55  56  57  58  59  60  61  62  65\n",
            "  66  68  69  70  72  73  74  75  77  78  79  80  81  83  86  89  90  91\n",
            "  92  94  95  96  97  98  99 100]\n",
            "[False  True False  True False  True False  True  True False  True False\n",
            "  True False  True False False  True False  True False False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True  True False  True False  True  True False  True False\n",
            "  True False  True False  True False  True  True False  True  True False\n",
            "  True False False  True False  True False False  True False  True False\n",
            "  True  True False  True False  True False  True]\n",
            "test\n",
            "[ 9 18 24 29 30 33 34 47 53 63 64 67 71 76 82 84 85 87 88 93]\n",
            "[False  True  True False  True False  True False False False  True False\n",
            " False  True  True  True False False  True False]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[  1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18  24\n",
            "  26  27  28  29  30  31  32  33  34  35  36  37  39  43  44  46  47  49\n",
            "  50  52  53  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
            "  70  71  72  73  74  75  76  78  79  80  81  82  83  84  85  87  88  91\n",
            "  93  94  95  96  97  98  99 100]\n",
            "[False  True False  True False  True False  True False  True  True False\n",
            "  True False  True False  True  True  True False  True False  True False\n",
            "  True False  True False  True False False False  True  True False False\n",
            "  True  True False False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True  True False  True False  True False  True False False  True False\n",
            " False  True False  True False  True False  True]\n",
            "test\n",
            "[11 19 20 21 22 23 25 38 40 41 42 45 48 51 54 77 86 89 90 92]\n",
            "[False False  True False  True False False  True  True False  True False\n",
            "  True False  True False  True False  True  True]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[ 2  5  6  9 10 11 12 13 14 16 18 19 20 21 22 23 24 25 26 27 28 29 30 31\n",
            " 33 34 36 37 38 39 40 41 42 44 45 47 48 49 50 51 52 53 54 55 57 58 59 60\n",
            " 62 63 64 65 66 67 69 70 71 72 73 74 75 76 77 79 80 82 83 84 85 86 87 88\n",
            " 89 90 91 92 93 94 96 98]\n",
            "[ True False  True False  True False  True False  True  True  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            " False  True  True False  True False  True False  True  True False False\n",
            "  True False  True False  True False  True False False  True False  True\n",
            "  True False  True False  True False False  True False  True False  True\n",
            " False  True False False  True  True False  True False  True False  True\n",
            " False  True False  True False  True  True  True]\n",
            "test\n",
            "[  1   3   4   7   8  15  17  32  35  43  46  56  61  68  78  81  95  97\n",
            "  99 100]\n",
            "[False False  True False  True False False  True False False  True  True\n",
            " False  True  True False False False False  True]\n",
            "-------------------------------------------------------------------------------s\n",
            "train\n",
            "[  1   3   4   6   7   8   9  11  12  13  15  17  18  19  20  21  22  23\n",
            "  24  25  26  27  28  29  30  32  33  34  35  36  38  40  41  42  43  44\n",
            "  45  46  47  48  49  50  51  52  53  54  55  56  57  60  61  62  63  64\n",
            "  66  67  68  71  76  77  78  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  95  96  97  99 100]\n",
            "[False False  True  True False  True False False  True False False False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True  True False  True False  True  True  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True  True False  True False  True False\n",
            "  True  True False  True False  True False  True False  True False  True\n",
            " False  True False False  True False False  True]\n",
            "test\n",
            "[ 2  5 10 14 16 31 37 39 58 59 65 69 70 72 73 74 75 79 94 98]\n",
            "[ True False  True  True  True False False False  True False False False\n",
            "  True  True False  True False False  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(inputs[200][1]).T.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gA_K36BIN6z9",
        "outputId": "bb7241b5-e3c9-4460-dd4f-bff8a2482067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data[0]) + len(data[2]) )\n",
        "print(len(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gMyQK0P0rEl",
        "outputId": "87c12b95-1419-458b-8c0f-6bdc08a8996e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10299\n",
            "10299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createLSTM(inputs, targets):\n",
        "\tiperparam = {\"verbose\": 0, \"epochs\": 15, \"batch_size\": 64}\n",
        "\tn_timesteps, n_features, n_outputs = inputs.shape[1], inputs.shape[2], targets.shape[1]\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\toutput = [model,iperparam]\n",
        "\treturn output\n",
        "\n",
        "def createCNNLSTM(inputs, targets):\n",
        "\tiperparam = {\"verbose\": 0, \"epochs\": 25, \"batch_size\": 64, \"n_steps\": 4, \"n_length\": 32, \"n_features\": 9}\n",
        "\tn_timesteps, n_features, n_outputs = inputs.shape[1], inputs.shape[2], targets.shape[1]\n",
        "\t# reshape data into time steps of sub-sequences\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,iperparam[\"n_length\"],n_features)))\n",
        "\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
        "\tmodel.add(TimeDistributed(Dropout(0.5)))\n",
        "\tmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "\tmodel.add(TimeDistributed(Flatten()))\n",
        "\tmodel.add(LSTM(100))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\toutput = [model,iperparam]\n",
        "\treturn output\n",
        "\n",
        "def createConvLSTM(inputs, targets):\n",
        "\t\t# define model\n",
        "\tiperparam = {\"verbose\": 0, \"epochs\": 25, \"batch_size\": 64, \"n_steps\": 4, \"n_length\": 32, \"n_features\": 9}\n",
        "\tn_timesteps, n_features, n_outputs = inputs.shape[1], inputs.shape[2], targets.shape[1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(iperparam[\"n_steps\"], 1, iperparam[\"n_length\"], n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\toutput = [model, iperparam]\n",
        "\treturn output"
      ],
      "metadata": {
        "id": "5CWpCm6CzZqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n",
        "from keras_tuner import RandomSearch\n",
        "def buildModel(hp):\n",
        "\t\t# define model\n",
        "\tiperparam = {\"verbose\": 0, \"epochs\": 25, \"batch_size\": 64, \"n_steps\": 4, \"n_length\": 32, \"n_features\": 9}\n",
        "\tn_timesteps, n_features, n_outputs = inputs.shape[1], inputs.shape[2], targets.shape[1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(iperparam[\"n_steps\"], 1, iperparam[\"n_length\"], n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(units=hp.Int('num_of_neurons',min_value=32,max_value=512,step=32), activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "tuner=RandomSearch(buildModel,\n",
        "    objective='accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='tuner1',\n",
        "    project_name='Clothing')\n",
        "trainX = data[0].reshape((data[0].shape[0], 4, 1, 32, 9))\n",
        "testX = data[2].reshape((data[2].shape[0], 4, 1, 32, 9))\n",
        "tuner.search(trainX,data[1],epochs=10,validation_data=(testX,data[3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "ToTFYjWUBWxL",
        "outputId": "1b55e0e0-2161-44f4-a906-83ce59129af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.2 MB/s \n",
            "\u001b[?25h\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "256               |?                 |num_of_neurons\n",
            "\n",
            "Epoch 1/10\n",
            " 66/230 [=======>......................] - ETA: 13s - loss: 0.7465 - accuracy: 0.6955"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ac56088ce94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crossValidation(witchModel):\n",
        "\tfrom keras.datasets import cifar10\n",
        "\tfrom keras.losses import sparse_categorical_crossentropy\n",
        "\tfrom keras.optimizers import Adam\n",
        "\tfrom sklearn.model_selection import KFold\n",
        "\timport numpy as np\n",
        "\n",
        "\tnum_folds = 5\n",
        "\tdata = load_dataset('HARDataset/')\n",
        "\n",
        "\t# Merge inputs and targets\n",
        "\tinputs = np.concatenate((data[0], data[2]), axis=0)\n",
        "\ttargets = np.concatenate((data[1], data[3]), axis=0)\n",
        "\n",
        "\t# Define the K-fold Cross Validator\n",
        "\tkfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "\t# K-fold Cross Validation model evaluation\n",
        "\tfold_no = 1\n",
        "\tacc_per_fold, loss_per_fold = [],[]\n",
        "\t#verbose, epochs, batch_size = 0, 15, 64\n",
        "\tfor train, test in kfold.split(inputs, targets):\n",
        "\t\n",
        "\t\tif(witchModel == 1):\n",
        "  \t# Define the model architecture\n",
        "\t\t\tlista = createLSTM(inputs, targets)\n",
        "\t\t\tmodel, iperparam = lista[0], lista[1]\n",
        "\t\t\ttrainX = inputs[train]\n",
        "\t\t\ttestX = inputs[test]\n",
        "\t\telif(witchModel == 2):\n",
        "\t\t\tlista = createCNNLSTM(inputs, targets)\n",
        "\t\t\tmodel, iperparam = lista[0], lista[1]\t\t\n",
        "\t\t\ttrainX = inputs[train].reshape((inputs[train].shape[0], iperparam[\"n_steps\"], iperparam[\"n_length\"], iperparam[\"n_features\"]))\n",
        "\t\t\ttestX = inputs[test].reshape((inputs[test].shape[0], iperparam[\"n_steps\"], iperparam[\"n_length\"], iperparam[\"n_features\"]))\n",
        "\t\telif(witchModel == 3):\n",
        "\t\t\tlista = createConvLSTM(inputs, targets)\n",
        "\t\t\tmodel, iperparam = lista[0], lista[1]\t\t\n",
        "\t\t\ttrainX = inputs[train].reshape((inputs[train].shape[0], iperparam[\"n_steps\"], 1, iperparam[\"n_length\"], iperparam[\"n_features\"]))\n",
        "\t\t\ttestX = inputs[test].reshape((inputs[test].shape[0], iperparam[\"n_steps\"], 1, iperparam[\"n_length\"], iperparam[\"n_features\"]))\n",
        "\t\n",
        "\t\tprint('------------------------------------------------------------------------')\n",
        "\t\tprint(f'Training for fold {fold_no} ...')\n",
        "\t\tprint('Number of train exaple:', inputs[train].shape[0])\n",
        "\t\tprint('Number of test exaple:', targets[test].shape[0])\n",
        "  \n",
        "  \t# Fit data to model\n",
        "\t\thistory = model.fit(trainX, targets[train],\n",
        "    \t          batch_size=iperparam[\"batch_size\"],\n",
        "      \t        epochs=iperparam[\"epochs\"],\n",
        "        \t      verbose=iperparam[\"verbose\"])\n",
        "  # Generate generalization metrics\n",
        "\t#\tscores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "\t\tscores = model.evaluate(testX, targets[test], verbose=0)\n",
        "\t\tprint(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\t\tacc_per_fold.append(scores[1] * 100)\n",
        "\t\tloss_per_fold.append(scores[0])\n",
        "\n",
        "  \t# Increase fold number\n",
        "\t\tfold_no = fold_no + 1\n",
        "\n",
        "\taverageAccuracy = f'{sum(acc_per_fold)/len(acc_per_fold):,.2f}'\n",
        "\taverageLoss = f'{sum(loss_per_fold)/len(loss_per_fold):,.4f}'\n",
        "\tprint('------------------------------------------------------------------------')\n",
        "\tprint('Average accuracy on {} folds: {}%' .format(num_folds, averageAccuracy))\n",
        "\tprint('Average loss on {} folds: {}' .format(num_folds, averageLoss))\n",
        "\treturn averageAccuracy, averageLoss"
      ],
      "metadata": {
        "id": "K9B7jKjB53Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "print(\"===================================================================\")\n",
        "print(\"                     LSTM                                          \")\n",
        "print(\"===================================================================\")\n",
        "lstmAccuracy, lstmLoss = crossValidation(1)\n",
        "print(\"===================================================================\")\n",
        "print(\"                     CLSTM                                         \")\n",
        "print(\"===================================================================\")\n",
        "clstmAccuracy, clstmLoss = crossValidation(2)\n",
        "print(\"===================================================================\")\n",
        "print(\"                     ConvLSTM                                          \")\n",
        "print(\"===================================================================\")\n",
        "convLstmAccuracy, convLstmLoss = crossValidation(3)\n",
        "compareModel = PrettyTable()\n",
        "compareModel.field_names = [\"Model\", \"Average Accuracy\", \"Average loss\"]\n",
        "compareModel.add_row([\"lstm\", lstmAccuracy, lstmLoss])\n",
        "compareModel.add_row([\"CLstm\", clstmAccuracy, clstmLoss])\n",
        "compareModel.add_row([\"Convlstm\", convLstmAccuracy, convLstmLoss])\n",
        "print(compareModel)"
      ],
      "metadata": {
        "id": "01Or958KFiqK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "36ae7a30-c1de-44b4-e0e8-1c812c9c087a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================================\n",
            "                     LSTM                                          \n",
            "===================================================================\n",
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Number of train exaple: 8239\n",
            "Number of test exaple: 2060\n",
            "Score for fold 1: loss of 0.13012756407260895; accuracy of 94.12621259689331%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Number of train exaple: 8239\n",
            "Number of test exaple: 2060\n",
            "Score for fold 2: loss of 0.1621762067079544; accuracy of 93.49514842033386%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Number of train exaple: 8239\n",
            "Number of test exaple: 2060\n",
            "Score for fold 3: loss of 0.13326263427734375; accuracy of 94.51456069946289%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Number of train exaple: 8239\n",
            "Number of test exaple: 2060\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-811f8b0c31bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"                     LSTM                                          \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlstmAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstmLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"                     CLSTM                                         \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-e4ac8d503e78>\u001b[0m in \u001b[0;36mcrossValidation\u001b[0;34m(witchModel)\u001b[0m\n\u001b[1;32m     48\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miperparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \t      verbose=iperparam[\"verbose\"])\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;31m# Generate generalization metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#       scores = model.evaluate(inputs[test], targets[test], verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compareModel"
      ],
      "metadata": {
        "id": "cV6-s0ieJb25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def confusionMatrix(predictions, testy):\n",
        "\ty_pred = np.argmax(predictions, axis=-1)\n",
        "\t#print(y_pred)\n",
        "\t#print(predictions)\n",
        "\ty_true=np.argmax(testy, axis=-1)\n",
        "\tcm = confusion_matrix(y_true, y_pred)\n",
        " ## Get Class Labels\n",
        "\tlabels = [\"Walking\", \"Walking upstairs\", \"Walking downstairs\",\n",
        "           \"Sitting\", \"Standing\", \"Laying\"]\n",
        "\tclass_names = labels\n",
        "\n",
        "# Plot confusion matrix in a beautiful manner\n",
        "\tfig = plt.figure(figsize=(16, 14))\n",
        "\tax= plt.subplot()\n",
        "\tsns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cells\n",
        "# labels, title and ticks\n",
        "\tax.set_xlabel('Predicted', fontsize=20)\n",
        "\tax.xaxis.set_label_position('bottom')\n",
        "\tplt.xticks(rotation=90)\n",
        "\tax.xaxis.set_ticklabels(class_names, fontsize = 10)\n",
        "\tax.xaxis.tick_bottom()\n",
        "\n",
        "\tax.set_ylabel('True', fontsize=20)\n",
        "\tax.yaxis.set_ticklabels(class_names, fontsize = 10)\n",
        "\tplt.yticks(rotation=0)\n",
        "\n",
        "\tplt.title('Confusion Matrix', fontsize=20)\n",
        "\n",
        "\tplt.show()\n",
        " \n",
        "# fit and evaluate a model\n",
        "def evaluate_LSTM_model(trainX, trainy, testX, testy):\n",
        "\tlista = createLSTM(trainX, trainy)\n",
        "\tmodel, hyperparam = lista[0],lista[1]\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=hyperparam['epochs'],\n",
        "           batch_size=hyperparam['batch_size'], verbose=hyperparam['verbose'])\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=hyperparam['batch_size'], verbose=0)\n",
        " \n",
        "\t#predictions = model.predict(testX)\n",
        "\t#confusionMatrix(predictions, testy)\n",
        "\treturn accuracy, model\n",
        "\n",
        "def evaluate_CNNLSTM_model(trainX, trainy, testX, testy):\n",
        "\t# define model\n",
        "\tlista = createCNNLSTM(trainX, trainy)\n",
        "\tmodel, hyperparam = lista[0], lista[1]\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape data into time steps of sub-sequences\n",
        "\tn_steps, n_length = 4, 32\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=hyperparam['epochs'], batch_size=hyperparam['batch_size'],\n",
        "           verbose=hyperparam['verbose'])\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=hyperparam['batch_size'], verbose=0)\n",
        "\treturn accuracy, model\n",
        "\n",
        "# fit and evaluate a model\n",
        "def evaluate_ConvLSTM_model(trainX, trainy, testX, testy):\n",
        "\t# define model\n",
        "\tlista = createConvLSTM(trainX, trainy)\n",
        "\tmodel, hyperparam = lista[0], lista[1]\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "\tn_steps, n_length = 4, 32\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=hyperparam['epochs'], batch_size=hyperparam['batch_size'],\n",
        "           verbose=hyperparam['verbose'])\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=hyperparam['batch_size'], verbose=0)\n",
        "\treturn accuracy, model\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\treturn m,s\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=10, selectModel=3):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset('HARDataset/')\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tbestScore = 0\n",
        "\n",
        "\tfor r in range(repeats):\n",
        "\t\tif selectModel == 1:\n",
        "\t\t\t\tscore, model = evaluate_LSTM_model(trainX, trainy, testX, testy)\n",
        "\t\telif selectModel == 2:\n",
        "\t\t\t\tscore, model = evaluate_CNNLSTM_model(trainX, trainy, testX, testy) \n",
        "\t\t\t\tn_steps, n_length, n_features = 4, 32, trainX.shape[2]\n",
        "\t\t\t\ttestX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
        "\t\telif selectModel == 3:\n",
        "\t\t\t\tscore, model = evaluate_ConvLSTM_model(trainX, trainy, testX, testy)   \n",
        "\t\t\t\tn_steps, n_length, n_features = 4, 32, trainX.shape[2]\n",
        "\t\t\t\ttestX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\t\tscore = score * 100.0\n",
        "\t\tif score > bestScore:\n",
        "\t\t\t\tbestScore = score\n",
        "\t\t\t\tbestModel = model\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\tpredictions = bestModel.predict(testX)\n",
        "\tconfusionMatrix(predictions, testy)\n",
        "\t# summarize results\n",
        "\treturn summarize_results(scores)"
      ],
      "metadata": {
        "id": "Dd_wrdvoz6bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "# run the experiment\n",
        "print(\"====================================================\")\n",
        "print(\"                     LSTM                           \")\n",
        "print(\"====================================================\")\n",
        "averageAccuracy1, var1 = run_experiment(10,1)\n",
        "print(\"====================================================\")\n",
        "print(\"                   CNNLSTM                          \")\n",
        "print(\"====================================================\")\n",
        "averageAccuracy2, var2 = run_experiment(10,2)\n",
        "print(\"====================================================\")\n",
        "print(\"                  ConvLSTM                          \")\n",
        "print(\"====================================================\")\n",
        "averageAccuracy3, var3 = run_experiment(10,3)\n",
        "compareModel = PrettyTable()\n",
        "compareModel.field_names = [\"Model\", \"Average Accuracy\", \"Variance\"]\n",
        "compareModel.add_row([\"lstm\", averageAccuracy1, var1])\n",
        "compareModel.add_row([\"CLstm\", averageAccuracy2, var2])\n",
        "compareModel.add_row([\"Convlstm\", averageAccuracy3, var3])\n",
        "print(compareModel)"
      ],
      "metadata": {
        "id": "--xsur-WiXza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}